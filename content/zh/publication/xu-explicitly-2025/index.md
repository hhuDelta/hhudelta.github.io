---
title: Explicitly Guided Information Interaction Network for Cross-Modal Point Cloud
  Completion
authors:
- Hang Xu
- Chen Long
- Wenxiao Zhang
- Yuan Liu
- Zhen Cao
- Zhen Dong
- Bisheng Yang
date: '2024-07-01'
publishDate: '2025-03-05T16:14:07.360283Z'
publication_types:
- paper-conference
publication: '*Proceedings of the European Conference on Computer Vision(CCF-A)*'
doi: 10.1007/978-3-031-73254-6_24
abstract: In this paper, we explore a novel framework, EGIInet (Explicitly Guided
  Information Interaction Network), a model for View-guided Point cloud Completion
  (ViPC) task, which aims to restore a complete point cloud from a partial one with
  a single view image. In comparison with previous methods that relied on the global
  semantics of input images, EGIInet efficiently combines the information from two
  modalities by leveraging the geometric nature of the completion task. Specifically,
  we propose an explicitly guided information interaction strategy supported by modal
  alignment for point cloud completion. First, in contrast to previous methods which
  simply use 2D and 3D backbones to encode features respectively, we unified the encoding
  process to promote modal alignment. Second, we propose a novel explicitly guided
  information interaction strategy that could help the network identify critical information
  within images, thus achieving better guidance for completion. Extensive experiments
  demonstrate the effectiveness of our framework, and we achieved a new state-of-the-art
  (+16% CD over XMFnet) in benchmark datasets despite using fewer parameters than
  the previous methods. The pre-trained model and code and are available at https://github.com/WHU-USI3DV/EGIInet.
---

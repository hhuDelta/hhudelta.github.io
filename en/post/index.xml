<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Latest News | Delta Lab</title><link>https://hhudelta.github.io/en/post/</link><atom:link href="https://hhudelta.github.io/en/post/index.xml" rel="self" type="application/rss+xml"/><description>Latest News</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 10 Dec 2024 00:00:00 +0000</lastBuildDate><image><url>https://hhudelta.github.io/media/icon_hu2210376920542963181.png</url><title>Latest News</title><link>https://hhudelta.github.io/en/post/</link></image><item><title>Congratulations to Li Hao and Xia Yuhang from our lab on the acceptance of their paper by AAAI 2025 (CCF-A)</title><link>https://hhudelta.github.io/en/post/24-12-10/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-12-10/</guid><description>&lt;p>&lt;strong>Deconfound Semantic Shift and Incompleteness in Incremental Few-shot Semantic Segmentation&lt;/strong>&lt;/p>
&lt;p>AAAI 2025 (CCF-A, a top conference in the field of Artificial Intelligence)&lt;/p>
&lt;p>Incremental Few-Shot Semantic Segmentation (IFSS) extends the segmentation capability of trained models, enabling them to segment images of new classes with few samples. However, during the incremental learning process, semantics may shift between background and object classes or vice versa. Additionally, when new classes differ significantly from pre-learned old classes, samples from new classes often lack representative feature attributes. In this paper, we propose a causal framework to discuss the causes of semantic shifts and incompleteness in IFSS and eliminate the revealed causal effects from two aspects. First, we introduce a Causal Intervention Module (CIM) to resist semantic shifts. CIM gradually and adaptively updates the prototypes of old classes, intervening to remove confounding factors. Secondly, we propose a Prototype Refinement Module (PRM) to complete missing semantics. In the PRM, knowledge obtained from the scene learning scheme helps integrate the features of new and old class prototypes. Experiments on the PASCAL-VOC 2012 and ADE20k benchmarks demonstrate the superior performance of our method.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-12-10-1.jpg" alt="AAAI 2025" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-12-10-2.jpg" alt="AAAI 2025" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-12-10-3.jpg" alt="AAAI 2025" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Professor Wu Yirui from our lab has been invited to serve as the Associate Editor of Computational Intelligence (CCF-C)</title><link>https://hhudelta.github.io/en/post/24-12-05/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-12-05/</guid><description>&lt;p>Computational Intelligence is a journal in the field of artificial intelligence that publishes original research on a wide range of experimental and theoretical topics in AI and computer science. The journal has a broad scope, covering areas such as machine learning, knowledge mining, network intelligence, artificial intelligence languages, and the philosophical impacts of AI. It is read by both researchers in the academic AI community and professionals in the industry.&lt;/p>
&lt;p>We welcome submissions from teachers and students!!!&lt;/p></description></item><item><title>Professor Wu Yirui from our lab was awarded the title of IEEE Senior Member</title><link>https://hhudelta.github.io/en/post/24-12-05-1/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-12-05-1/</guid><description>&lt;p>Professor Wu Yirui from our lab was awarded the title of IEEE Senior Member&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-12-5.jpg" alt="IEEE Senior Member" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Congratulations to student Shi Guangchen on winning the Outstanding Academic Master's Degree in Jiangsu Province and the Outstanding Master's Thesis of Jiangsu Computer Society</title><link>https://hhudelta.github.io/en/post/24-11-27/</link><pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-11-27/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-11-27-1.jpg" alt="sgc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-11-27-2.jpg" alt="sgc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Congratulations to Kong Qiran on their work published in TCBB being recognized as a Highly Cited Paper</title><link>https://hhudelta.github.io/en/post/24-11-19/</link><pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-11-19/</guid><description>&lt;p>Kong Qiran&amp;rsquo;s paper &amp;ldquo;CDT-CAD: Context-Aware Deformable Transformers for End-to-End Chest Abnormality Detection on X-Ray Images,&amp;rdquo; published in TCBB, has been recognized as an ESI Highly Cited Paper.&lt;/p></description></item><item><title>Professor Wu Yirui from our lab was awarded the 2024 Jiangsu Province Young Science and Technology Talent Support Project</title><link>https://hhudelta.github.io/en/post/24-11-7/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-11-7/</guid><description>&lt;p>The Jiangsu Province Young Science and Technology Talent Support Project (Youth Support Project) is an important talent program aiming to cultivate and select outstanding young science and technology talents.&lt;/p>
&lt;p>This project mainly targets young scientific researchers within Jiangsu Province, especially those who are under 35 years old and have remarkable achievements and development potential in fields such as natural sciences and engineering technologies. Through measures like providing financial support, building scientific research platforms, organizing academic exchanges and talent cultivation, the Youth Support Project aims to help young science and technology talents grow rapidly and become leading figures in the field of science and technology. Since its implementation, the Youth Support Project has cultivated a number of young science and technology talents with influence both at home and abroad, and has contributed significantly to the economic and social development of Jiangsu Province and even the whole country.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-11-7.jpg" alt="TNSM" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Professor Wu Yirui from our lab was awarded the 2024 Youth Science and Technology Award of Jiangsu Information Technology Application Society</title><link>https://hhudelta.github.io/en/post/24-11-7-2/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-11-7-2/</guid><description>&lt;p>At the &amp;ldquo;3rd Jiangsu Information Technology Application Conference&amp;rdquo; held at Nanjing University on November 7, 2024, Professor Wu Yirui was awarded the Youth Science and Technology Award of Jiangsu Computer Society in recognition of his innovative achievements in the field of few-shot learning.&lt;/p>
&lt;p>This conference highly values the scientific research and application of information technology. It gathers experts from universities, scientific research institutions and enterprises both inside and outside the province, and is committed to building a multi-level cooperation platform in the field of information technology, injecting new vitality into technological innovation and achievement transformation. Professor Wu Yirui&amp;rsquo;s achievements focus on theoretical expansion, platform design, practical application and technology promotion in few-shot learning. He actively leads platform construction, promotes the efficient application of technological achievements in industries such as water conservancy, and promotes industry integration through high-level academic forums, driving new breakthroughs in this field.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-11-7-1.jpg" alt="TNSM" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Dr. Liu Xinfu from our lab attended the CCF CAD/CG2024 conference in Nanchang and gave an oral presentation</title><link>https://hhudelta.github.io/en/post/24-08-15/</link><pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-08-15/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c8-15-lxf.jpg" alt="TNSM" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
The 27th National Conference on Computer-Aided Design and Computer Graphics (CCF CAD/CG 2024), organized by the China Computer Federation (CCF) and co-hosted by the CCF Computer-Aided Design and Graphics Committee, East China Jiaotong University, Zhejiang University Nanchang Research Institute (Jiangxi Qiushi Advanced Research Institute), National Virtual Reality Innovation Center, Nanchang University of Aeronautics, and China Mobile Virtual Reality Innovation Center, will be held in Nanchang, Jiangxi, from August 15 to August 18, 2024. This conference will be held concurrently with the 16th National Conference on Geometric Design and Computing (GDC 2024). The conference aims to support the modernization of the industrial chain in Jiangxi under the &amp;ldquo;1269 Action Plan&amp;rdquo; and build Nanchang into a high-tech hub for information technology industries. The conference will bring together experts, scholars, technical innovators, and manufacturing pioneers from multiple fields to discuss the innovative applications and development of VR technology in the manufacturing industry.&lt;/p>
&lt;p>As a flagship event for the computer-aided design and computer graphics community in China, this conference seeks to accelerate the integration of new-generation information technology with the manufacturing industry, support the digital transformation of manufacturing enterprises, and promote the innovation and popularization of VR technology. The conference aims to introduce intelligent technologies and systems to improve the efficiency and quality of manufacturing and establish Nanchang as a hub for the information technology industry.&lt;/p>
&lt;p>The paper co-authored by Dr. Liu Xinfu and Qin Rui from our lab was accepted for an oral presentation at CCF CAD/CG 2024 and has been recommended to the Journal of Shanghai Jiao Tong University.&lt;/p></description></item><item><title>Congratulations to Qin Rui on his paper being accepted by the Journal of Shanghai Jiao Tong University (English Edition).</title><link>https://hhudelta.github.io/en/post/24-08-14/</link><pubDate>Wed, 14 Aug 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-08-14/</guid><description>&lt;p>Hyperspectral Image Classification Method Based on Global Space-spectral Attention Mechanism&lt;/p>
&lt;p>abstract：In hyperspectral remote sensing images, the interactions between pixels within a defined spatial range lead to the mixing of adjacent pixels. Additionally, the high similarity between adjacent spectra results in information redundancy, which hinders the extraction of global spatial and spectral correlations. To address the issues of adjacent pixel mixing and spectral redundancy, this paper proposes a hyperspectral image classification method based on a global spatial-spectral attention mechanism.&lt;/p>
&lt;p>First, the global spatial attention module in the proposed method uses multi-scale dilated convolutions to obtain a larger receptive field, capturing global spatial correlations and extracting unmixed pixel information. Then, the global spectral attention module designs a spectral domain partitioning algorithm, which uses the product of local density and information entropy as a threshold to divide the spectrum into scattered subsets, eliminating redundant information. This approach fully utilizes the global contextual information of the entire spectral band and extracts the correlation of global spectral information.&lt;/p>
&lt;p>Finally, these two modules are combined to obtain the global correlations of both space and spectrum. Experimental results show that the proposed method achieves overall accuracies of 97.28%, 94.73%, and 95.76% on three WHU-Hi hyperspectral datasets, outperforming the comparison methods.&lt;/p></description></item><item><title>Congratulations to Cao Hao for his paper being accepted by TNSM</title><link>https://hhudelta.github.io/en/post/24-08-10/</link><pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-08-10/</guid><description>&lt;p>Edge Computing and Few-shot Learning Featured Intelligent Framework in Digital Twin empowered Mobile Networks&lt;/p>
&lt;p>Journal：IEEE Transactions on Network and Service Management(中科院2区)
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c8-10-TNSM.jpg" alt="TNSM" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Digital twins (DT) and mobile networks have evolved forms of intelligence in Internet of Things (IoT). In this work, we consider a Digital Twin Mobile Network (DTMN) scenario with few multimedia samples. Facing challenges of knowledge extraction with few samples, stable interaction with dynamic changes of multimedia data, time and privacy saving in low-resource mobile network, we propose an edge computing and few-shot learning featured intelligent framework. Considering time-sensitive property of transmission and privacy risks of directly uploads in mobile network, we deploy edge computing to locally run networks for analysis, thus saving time to offload computing request and enhancing privacy by encrypting original data. Inspired by remarkable relationship representation of graphs, we build Graph Neural Network (GNN) in cloud to map physical mobile systems to virtual entities with DT, thus performing semantic inferences in cloud with few samples uploaded by edges. Occasionally, node features in GNN could converge to similar, non-discriminative embeddings, causing catastrophic unstable phenomena. An iterative reweight and drop structure (IRDS) is thus constructed in cloud, which nonetheless contributes stability with respect to edge uncertainty. As part of IRDS, a drop Edge&amp;amp;Node scheme is proposed to randomly remove certain nodes and edges, which not only enhances distinguished capability of graph neighbor patterns, but also offers data encryption with random strategy. We show one implementation case of image classification in social network, where experiments on public datasets show that our framework is effective with user-friendly advantages and significant intelligence.&lt;/p></description></item><item><title>Several students from our lab participated in the China Yancheng Innovation and Entrepreneurship Competition</title><link>https://hhudelta.github.io/en/post/24-07-26/</link><pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-07-26/</guid><description>&lt;p>The China Yancheng Innovation and Entrepreneurship Competition, hosted by the Yancheng Municipal Government, aims to promote regional innovation development, attract global talent, and facilitate the transformation of scientific and technological achievements. The competition focuses on multiple high-tech fields and enhances the city&amp;rsquo;s image and economic development through multi-stage selection and diversified support, while also fostering and incubating innovative talent.&lt;/p>
&lt;p>Dr. Liu Xinfu, along with students Jin Xiu and Geng Ao from our lab, presented three industry-academia-research projects at the finals.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-7-26-1.jpg" alt="yc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c24-7-26-2.jpg" alt="yc" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Professor Wu Yirui from our lab was invited to deliver a keynote speech on Few-shot Visual Learning at the International Symposium on IoT and Smart Cities</title><link>https://hhudelta.github.io/en/post/24-06-22-isitsc/</link><pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-06-22-isitsc/</guid><description>&lt;p>Thank you to the International Symposium on IoT and Smart Cities (ISITSC 2024) for the invitation. We warmly welcome everyone to join the event in person at: Nanjing Jinfan Wanyuan Hotel, 47-1 Pailou Alley, Gulou District, Nanjing, Jiangsu Province (near Hanzhongmen Metro Station, Jiangsu Provincial Hospital of Traditional Chinese Medicine).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c6-22-isitsc-1.jpg" alt="ISITSC" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c6-22-isitsc-2.jpg" alt="ISITSC" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="%5cnews%5c6-22-isitsc-3.jpg" alt="ISITSC" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>One paper published in TECS becomes ESI highly cited paper</title><link>https://hhudelta.github.io/en/post/24-05-22-tecs-high-cited/</link><pubDate>Wed, 22 May 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-05-22-tecs-high-cited/</guid><description>&lt;p>Paper published in TECS &amp;ldquo;Edge-AI-Driven Framework with Efficient Mobile Network Design for Facial Expression Recognition&amp;rdquo; becomes ESI highly cited paper. This is our forth paper for ESI highly cited paper.&lt;/p></description></item><item><title>CCF Nanjing Chapter Public Forum: Empowering New Productivity with Large Models</title><link>https://hhudelta.github.io/en/post/24-05-11-ccf-forum/</link><pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-05-11-ccf-forum/</guid><description>&lt;p>We have organized a forum about language and vision big model in Hohai University, Jiangning Campus. We have been grateful to invite Professor Guilin Qi from Southeast University and Professor Liming Wang from Nanjing University. Hope to see you in Nanjing.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="screen reader text" srcset="
/en/post/24-05-11-ccf-forum/featured_hu13568130864249315420.webp 400w,
/en/post/24-05-11-ccf-forum/featured_hu17881180666531369831.webp 760w,
/en/post/24-05-11-ccf-forum/featured_hu3691162443052204626.webp 1200w"
src="https://hhudelta.github.io/en/post/24-05-11-ccf-forum/featured_hu13568130864249315420.webp"
width="441"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="screen reader text" srcset="
/en/post/24-05-11-ccf-forum/luntan-hohai_hu12094426662717314787.webp 400w,
/en/post/24-05-11-ccf-forum/luntan-hohai_hu16396791309368695668.webp 760w,
/en/post/24-05-11-ccf-forum/luntan-hohai_hu16348998797441291927.webp 1200w"
src="https://hhudelta.github.io/en/post/24-05-11-ccf-forum/luntan-hohai_hu12094426662717314787.webp"
width="487"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Our team has attented VALSE2024 in Chongqing City</title><link>https://hhudelta.github.io/en/post/24-05-06-valse/</link><pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-05-06-valse/</guid><description/></item><item><title>One paper published in TOIT becomes ESI highly cited paper</title><link>https://hhudelta.github.io/en/post/24-03-15-toit-high-cited/</link><pubDate>Fri, 15 Mar 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-03-15-toit-high-cited/</guid><description>&lt;p>Paper published in TOIT &amp;ldquo;Digital Twin of Intelligent Small Surface Defect Detection with Cyber-Manufacturing Systems&amp;rdquo; becomes ESI highly cited paper. This is our third paper for ESI highly cited paper.&lt;/p></description></item><item><title>One paper published in TNSE becomes ESI hot paper</title><link>https://hhudelta.github.io/en/post/24-03-10-tnse-hot-paper/</link><pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/24-03-10-tnse-hot-paper/</guid><description>&lt;p>Paper published in TNSE &amp;ldquo;Edge Computing Driven Low-Light Image Dynamic Enhancement for Object Detection&amp;rdquo; becomes ESI hot paper. This is our first paper for ESI hot paper.&lt;/p></description></item><item><title>One paper published in TNSE becomes ESI highly cited paper</title><link>https://hhudelta.github.io/en/post/23-12-22-tnse-high-cited/</link><pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate><guid>https://hhudelta.github.io/en/post/23-12-22-tnse-high-cited/</guid><description>&lt;p>Paper published in TNSE &amp;ldquo;Edge Computing Driven Low-Light Image Dynamic Enhancement for Object Detection&amp;rdquo; becomes ESI highly cited paper. This is our second paper for ESI highly cited.&lt;/p></description></item></channel></rss>
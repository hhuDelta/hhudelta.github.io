@article{LI2023110,
title = {Interpretable thoracic pathologic prediction via learning group-disentangled representation},
journal = {Methods},
volume = {218},
pages = {110-117},
year = {2023},
issn = {1046-2023},
doi = {https://doi.org/10.1016/j.ymeth.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1046202323001305},
author = {Hao Li and Yirui Wu and Hexuan Hu and Hu Lu and Qian Huang and Shaohua Wan},
keywords = {Disentangled representation learning, Group-disentangled feature representation, Thoracic pathologic prediction},
abstract = {Deep learning has brought a significant progress in medical image analysis. However, their lack of interpretability might bring high risk for wrong diagnosis with limited clinical knowledge embedding. In other words, we believe it's crucial for humans to interpret how deep learning work for medical analysis, thus appropriately adding knowledge constraints to correct the bias of wrong results. With such purpose, we propose Representation Group-Disentangling Network (RGD-Net) to explain the process of feature extraction and decision making inside deep learning framework, where we completely disentangle feature space of input X-ray images into independent feature groups, and each group would contribute to diagnose of a specific disease. Specifically, we first state problem definition for interpretable prediction with auto-encoder structure. Then, group-disentangled representations are extracted from input X-ray images with the proposed Group-Disentangle Module, which constructs semantic latent space by enforcing semantic consistency of attributes. Afterwards, adversarial constricts on mapping from features to diseases are proposed to prevent model collapse during training. Finally, a novel design of local tuning medical application is proposed based on RGB-Net, which is capable to aid clinicians for reasonable diagnosis. By conducting quantity of experiments on public datasets, RGD-Net have been superior to comparative studies by leveraging potential factors contributing to different diseases. We believe our work could bring interpretability in digging inherent patterns of deep learning on medical image analysis.}
}